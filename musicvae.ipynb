{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:38.580850Z",
     "start_time": "2020-12-07T19:53:23.313440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import magenta.music as mm\n",
    "from magenta.models.music_vae import TrainedModel, configs\n",
    "from magenta.music import DEFAULT_STEPS_PER_BAR\n",
    "from magenta.music.protobuf.music_pb2 import NoteSequence\n",
    "from six.moves import urllib\n",
    "from typing import List\n",
    "from note_sequence_utils import save_midi, save_plot\n",
    "\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:38.593798Z",
     "start_time": "2020-12-07T19:53:38.583824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download Magenta checkpoint to target directory\n",
    "def download_checkpoint(model, checkpoint, target_dir):\n",
    "    \n",
    "    tf.io.gfile.makedirs(target_dir)\n",
    "    checkpoint_target = os.path.join(target_dir, checkpoint)\n",
    "    \n",
    "    if not os.path.exists(checkpoint_target):\n",
    "        \n",
    "        response = urllib.request.urlopen(\"https://storage.googleapis.com/magentadata/models/{}/checkpoints/{}\".format(model, checkpoint))\n",
    "        data = response.read()\n",
    "        file = open(checkpoint_target, 'wb')\n",
    "        file.write(data)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:38.601777Z",
     "start_time": "2020-12-07T19:53:38.596790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "def get_model(model):\n",
    "    \n",
    "    checkpoint = model + \".tar\"\n",
    "    download_checkpoint(\"music_vae\", checkpoint, \"checkpoints\")\n",
    "    \n",
    "    return TrainedModel(configs.CONFIG_MAP[model.split(\".\")[0] if \".\" in model else model],\n",
    "                        batch_size = 8, checkpoint_dir_or_path = os.path.join(\"checkpoints\", checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:38.606770Z",
     "start_time": "2020-12-07T19:53:38.602774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample method\n",
    "def sample(model_name, steps_per_sample):\n",
    "    \n",
    "    model = get_model(model_name)\n",
    "    sample_seq = model.sample(n = 2, length = steps_per_sample, temperature = 1.1)\n",
    "    \n",
    "    save_midi(sample_seq, \"sample\", model_name)\n",
    "    save_plot(sample_seq, \"sample\", model_name)\n",
    "    \n",
    "    return sample_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:38.615767Z",
     "start_time": "2020-12-07T19:53:38.608760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Interpolate method -> takes two sequeneces and interpolates between them\n",
    "def interpolate(model_name, sample_seq : List[NoteSequence], steps_per_sample, n_output, n_bars):\n",
    "    \n",
    "    if len(sample_seq) != 2:\n",
    "        raise Exception('Expected 2 sequences, actual sequences : {}'.format(len(sample_seq)))\n",
    "    \n",
    "    if not sample_seq[0].notes or not sample_seq[1].notes:\n",
    "        raise Exception('None. \\nSequence 1 has length : {} \\nSequence 2 has length : {}'.format(\n",
    "        len(sample_seq[0].notes), len(sample_seq[1].notes)))\n",
    "        \n",
    "    model = get_model(model_name)\n",
    "    \n",
    "    interpolate_sequences = model.interpolate(start_sequence = sample_seq[0], \n",
    "                                        end_sequence = sample_seq[1],\n",
    "                                        num_steps = n_output,\n",
    "                                        length = steps_per_sample)\n",
    "    save_midi(interpolate_sequences, \"interpolate\", model_name)\n",
    "    save_plot(interpolate_sequences, \"interpolate\", model_name)\n",
    "    \n",
    "    interpolate_seq = mm.sequences_lib.concatenate_sequences(interpolate_sequences, [4] * n_output)\n",
    "    save_midi(interpolate_seq, \"merge\", model_name)\n",
    "    save_plot(interpolate_seq, \"merge\", model_name, plot_max_length_bar = n_bars, bar_fill_alphas = [0.50, 0.50, 0.05, 0.05])\n",
    "    \n",
    "    return interpolate_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:38.622720Z",
     "start_time": "2020-12-07T19:53:38.616737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Groove method -> adds groove to interpolated sequence by splitting in chunks\n",
    "def groove(model_name, interpolate_seq, steps_per_sample, n_output, n_bars):\n",
    "    \n",
    "    model = get_model(model_name)\n",
    "    \n",
    "    split_interpolated_seq = mm.sequences_lib.split_note_sequence(interpolate_seq, 4)\n",
    "    \n",
    "    if len(split_interpolated_seq) != n_output:\n",
    "        raise Exception('Wrong interpolation size. Expected is 10, actual is {}'.format(split_interpolated_seq))\n",
    "            \n",
    "    encoding, mu, sigma = model.encode(note_sequences = split_interpolated_seq)\n",
    "    \n",
    "    groove_sequences = model.decode(z = encoding, length = steps_per_sample)\n",
    "    groove_seq = mm.sequences_lib.concatenate_sequences(groove_sequences, [4] * n_output)\n",
    "    \n",
    "    save_midi(groove_seq, \"groove\", model_name)\n",
    "    save_plot(groove_seq, \"groove\", model_name, plot_max_length_bar = n_bars, \n",
    "              show_velocity = True, bar_fill_alphas = [0.50, 0.50, 0.05, 0.05])\n",
    "    \n",
    "    return groove_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:38.627719Z",
     "start_time": "2020-12-07T19:53:38.623717Z"
    }
   },
   "outputs": [],
   "source": [
    "n_output = 6\n",
    "n_bar_per_sample = 2\n",
    "n_steps_per_sample = n_bar_per_sample * DEFAULT_STEPS_PER_BAR\n",
    "n_bars = n_output * n_bar_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:41.037496Z",
     "start_time": "2020-12-07T19:53:38.630701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 8, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [512]\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\magenta\\models\\music_vae\\lstm_utils.py:39: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [256, 256]\n",
      "\n",
      "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\magenta\\models\\music_vae\\lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\magenta\\models\\music_vae\\lstm_utils.py:99: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\magenta\\contrib\\rnn.py:751: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\magenta\\contrib\\rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow_core\\python\\ops\\linalg\\linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "WARNING:tensorflow:From c:\\users\\siddh\\anaconda3\\envs\\magenta\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not call `graph_parents`.\n",
      "INFO:tensorflow:Unbundling checkpoint.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\siddh\\AppData\\Local\\Temp\\tmpip9jhiac\\cat-drums_2bar_small.lokl.ckpt\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\sample\\cat-drums_2bar_small.lokl_00_2020-12-07_145340.mid\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\sample\\cat-drums_2bar_small.lokl_01_2020-12-07_145340.mid\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\sample\\cat-drums_2bar_small.lokl_00_2020-12-07_145340.html\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\sample\\cat-drums_2bar_small.lokl_01_2020-12-07_145340.html\n"
     ]
    }
   ],
   "source": [
    "generated_sample_sequences = sample(\"cat-drums_2bar_small.lokl\", n_steps_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:42.221330Z",
     "start_time": "2020-12-07T19:53:41.038493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 8, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [512]\n",
      "\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [256, 256]\n",
      "\n",
      "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
      "INFO:tensorflow:Unbundling checkpoint.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\siddh\\AppData\\Local\\Temp\\tmp_foy8l20\\cat-drums_2bar_small.hikl.ckpt\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_00_2020-12-07_145341.mid\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_01_2020-12-07_145341.mid\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_02_2020-12-07_145341.mid\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_03_2020-12-07_145341.mid\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_04_2020-12-07_145341.mid\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_05_2020-12-07_145341.mid\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_00_2020-12-07_145341.html\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_01_2020-12-07_145341.html\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_02_2020-12-07_145341.html\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_03_2020-12-07_145341.html\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_04_2020-12-07_145342.html\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\interpolate\\cat-drums_2bar_small.hikl_05_2020-12-07_145342.html\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\merge\\cat-drums_2bar_small.hikl_00_2020-12-07_145342.mid\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\merge\\cat-drums_2bar_small.hikl_00_2020-12-07_145342.html\n"
     ]
    }
   ],
   "source": [
    "generate_interpolate_seq = interpolate(\"cat-drums_2bar_small.hikl\",\n",
    "                                       generated_sample_sequences, \n",
    "                                       n_steps_per_sample, n_output, n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:53:43.130899Z",
     "start_time": "2020-12-07T19:53:42.222328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, GrooveLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 8, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 0.3, 'sampling_schedule': 'constant', 'sampling_rate': 0.0, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [512]\n",
      "\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [256, 256]\n",
      "\n",
      "INFO:tensorflow:Unbundling checkpoint.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\siddh\\AppData\\Local\\Temp\\tmp4rkfkco4\\groovae_2bar_humanize/model.ckpt-3061\n",
      "Generated midi : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\groove\\groovae_2bar_humanize_00_2020-12-07_145343.mid\n",
      "Generated plot : C:\\Users\\siddh\\Documents\\GitHub\\magenta_project\\output\\groove\\groovae_2bar_humanize_00_2020-12-07_145343.html\n"
     ]
    }
   ],
   "source": [
    "generate_groove_sequece = groove(\"groovae_2bar_humanize\",\n",
    "                                 generate_interpolate_seq,\n",
    "                                 n_steps_per_sample, n_output, n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
